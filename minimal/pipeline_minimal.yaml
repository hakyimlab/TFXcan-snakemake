
---
pipeline_dir: '/beagle3/haky/users/temi/projects/TFXcan-snakemake'
runname: 'minimal_gwas' # change this to the name of your project
date: "2024-12-11" # if not provided will be set to the current date
metadata: "/beagle3/haky/users/temi/projects/TFXcan-snakemake/metadata/metadata_pcrisk.txt" # the metadata file for the project
scratch_dir: "/scratch/midway3/temi" # a folder that will be used to save large and temporary files
delete_enformer_outputs: False # should you delete enformer predictions after aggregating them? Saves disk space
personalized_predictions: True # should you run personalized predictions?
runSusie: False # by default, we do not run SuSiE but this will be changed in the future

enpact_weights: /beagle3/haky/users/temi/projects/Enpact/files/ENPACT_734_2024-07-26.compiled_weights.lambda.1se.txt.gz # the weights file for Enpact

rscript: "/beagle3/haky/users/shared_software/TFXcan-pipeline-tools/bin/Rscript" # not necessary (dependency will be removed)

# genome file
genome:
  fasta: "/project2/haky/Data/hg_sequences/hg38/Homo_sapiens_assembly38.fasta"

# by default finemapping is not done, but the 
finemapping:
  LD_blocks: "/beagle3/haky/users/temi/projects/TFXcan-snakemake/metadata/EUR_LDBlocks.hg38.updated.bed"
  genotypes_dosages_pattern: '/project2/haky/Data/1000G/population_data/EUR/bfiles/ALL.chr{}.shapeit2_integrated_SNPs_v2a_27022019.GRCh38.phased.geno.txt.gz'

# necessities for predictdb
predictdb:
  blacklist_regions: /beagle3/haky/users/temi/projects/TFXcan-snakemake/metadata/HLA_blocks.txt
  conda_environment: /beagle3/haky/users/temi/software/conda_envs/predictdb_env
  nextflow_main_executable: /beagle3/haky/users/temi/projects/TFXcan-snakemake/workflow/PredictDb-nextflow/main.nf
  reference_genotypes: /project2/haky/Data/1000G/population_data/EUR/annot_files/EUR.geno.txt
  reference_annotations: /project2/haky/Data/1000G/population_data/EUR/annot_files/EUR.snp_annot.txt

# necessities for summary-TFXcan
summaryTFXcan:
  conda_environment: /beagle3/haky/users/temi/software/conda_envs/imlabtools
  summaryXcan_executable: /beagle3/haky/users/temi/software/MetaXcan/software/SPrediXcan.py # this is the SPrediXcan.py script

# necessities for Enformer
enformer: 
  base_directives: "config/enformer_base.yaml"
  personalized_directives: "config/personalized_base.yaml"
  model: "/project2/haky/Data/enformer/raw"
  predict: "/beagle3/haky/users/shared_pipelines/enformer_pipeline_aggregate/scripts/enformer_predict.py"
  aggregate: "workflow/src/aggregate.py"
  aggtype: "aggByCollect"
...
